---
title: "Case: Agricultural Data"
date: "`Sys.Date()`"
output:
  html_document
---

```{r setup, warning = FALSE, message = FALSE}
library(agridat) # various ag data sets
library(sommer) # for fitting mixed models
library(tidyverse)
library(ggplot2)
library(lme4)
library(expm)
library(Matrix)
library(MASS)
data(bridges.cucumber)
df <- bridges.cucumber %>% 
  mutate(rowf = factor(row),
         colf = factor(col))
A <- diag(nlevels(df$gen))
rownames(A) <- colnames(A) <- levels(df$gen)
```

```{r data-summary}
skimr::skim(df)
```

```{r groups descp}
group <- df %>% group_by(loc, gen) %>% tally()
```

```{r model}
fit <- mmer(yield ~ 1 + loc,
            # random: random effects
            # vs(ds(x), y): diagonal covariance structure for the "y" covariate for all 
            # levels of the factor covariate "x"
            random =~ vs(ds(loc), gen, Gu = A),
            # rcov: error term
            rcov =~ units,
            data = df)

summary(fit)
```


```{r fit}
randef(fit)

# data frame of fixed effects (BLUEs)
as.vector(fit$Beta)

# list for each random effect (BLUPs)
fit$U

# residual values (Marginal residuals)
fit$residuals

plot(fit)
```
```{r values}
y <- df$yield
X <- model.matrix(~loc, data = df)
beta_hat <- fit$Beta$Estimate
Z <- model.matrix(~gen:loc -1, data = df)
b_hat <- unlist(fit$U)

N <- length(y) # number of observation
n <- nrow(group) # number of groups indicates i = 1, 2, 3, ..., 8
n.levels <- unique(group$n) # number of obervations within each group
p <- ncol(X) # number of vector of fixed effects
q <- ncol(Z) # number of vector of random effects

fitted <-  fit$fitted[,1] # fitted/predicted value of y
# predy <- X %*% beta_hat
# all(fitted == predy) ## TRUE
yi <- vector("list", n)
for (i in 1:n){
  yi[[i]] <- y[(i*4-3):(i*4)]
}

Xi <- vector("list", n)
for (i in 1:n){
  Xi[[i]] <- X[(i*4-3):(i*4),]
}
```

```{r V}
options(max.print=999999)
# Covariance matrix of Y (denote as V,\Omega)
V <- solve(fit$Vi)
iV <- fit$Vi

# variance for each group...
Omgi <- vector("list", n)
for (i in 1:n){
  Omgi[[i]] <- V[(i*4-3):(i*4),(i*4-3):(i*4)]
}
```

```{r Q}
var.beta <- solve((t(X) %*% iV %*% X)) # predicted variance of fixed effect
# var.beta <- fit$VarBeta
Q <- iV - iV %*% X %*% var.beta %*% t(X) %*% iV
```

```{r residuals(marginal and conditional)}
# marginal residuals
resm <- y - X %*% beta_hat
#all(resm == fit$residuals)
resm.i <- vector("list", n) # same as resm
for (i in 1:n){
  resm.i[[i]] <- yi[[i]] - Xi[[i]]%*%beta_hat
}

# conditional residuals
resc <- y - X %*% beta_hat - Z %*% b_hat
```

```{r variance of marginal residuals}
var.resm <- V - X %*% solve((t(X) %*% iV %*% X)) %*% t(X)
```

```{r standardised marginal residuals}
std.resm <- resm/sqrt(diag(var.resm))
```

```{r Verbeke..}
vareps.i <- vector("list", n)
for (i in 1:n){
  vareps.i[[i]] <- expm::sqrtm(Omgi[[i]]) %*% resm.i[[i]]
}

Verbeke.i <- vector("list", n)
for (i in 1:n){
  Verbeke.i[[i]] <- norm(diag(1,4,4) - vareps.i[[i]] %*% t(vareps.i[[i]]), type = "2")
}

Ver.star <- sqrt(unlist(Verbeke.i))
```


```{r plot1}
plot(fitted, std.resm, xlab = "Marginal fitted values",
     ylab = "Standardized marginal residuals",
     pch = 20, cex = 1.2, cex.lab = 1.2, cex.axis = 1.3,
     ylim = c(-1.3*max(abs(range(std.resm))),1.3*max(abs(range(std.resm)))))
abline(h = 0, lty = 3)
```

```{r plot2}
plot(1:nrow(df), std.resm, xlab = "Observation indices",
     ylab = "Standardized marginal residuals",
     pch = 20, cex = 1.2, cex.lab = 1.2, cex.axis = 1.3,
     ylim = c(-1.3*max(abs(range(std.resm))),1.3*max(abs(range(std.resm)))))
abline(h = 0, lty = 3)
```

```{r plot3}
plot(1:n, Ver.star, xlab = "Unit indicies",
     ylab = "Standardused measure of adequacy",
     pch = 20, cex = 1.2, cex.lab = 1.2, cex.axis = 1.3,
     ylim = c(-1.3*max(abs(range(Ver.star))),1.3*max(abs(range(Ver.star)))))
abline(h = 0, lty = 3)
```

```{r variance of conditional residuals}
mat1 <- matrix(c(as.vector(fit$VarU[[1]]$yield), rep(0, 16)), 4, 8)
mat2 <- matrix(c(rep(0, 16), as.vector(fit$VarU[[2]]$yield)), 4, 8)
Gam <- rbind(mat1, mat2)

R <- V - Z %*% Gam %*% t(Z)

var.resc <- R %*% Q %*% R
```

```{r standardised conditional residuals}
std.resc <- resc/sqrt(diag(var.resc))
```


```{r Fraction of confouding}
ident <- diag(N)
auxnum <- R %*% Q %*% Z %*% Gam %*% t(Z) %*% R
auxden <- R %*% Q %*% R
CF <- diag(auxnum)/diag(auxden)
```

```{r squart root of a matrix}
sqrt.matrix <- function(mat) {
                mat <- as.matrix(mat)
                singular_dec <- svd(mat,LINPACK = F)
                U <- singular_dec$u
                V <- singular_dec$v
                D <- diag(singular_dec$d)
                sqrtmatrix <- U %*% sqrt(D) %*% t(V)
        }
```


```{r least confounded residuals ???}
R.half <- sqrt.matrix(R)

# R_half <- expm::sqrtm(R)

auxqn <- eigen((R.half %*% Q %*% R.half), symmetric = T, only.values = FALSE)

lt <- sqrt(solve(diag((auxqn$values[1:(N-p)])))) %*% t(auxqn$vectors[1:N,1:(N-p)]) %*% solve(sqrt.matrix(R[1:N,1:N]))

var.resmcp <- lt %*% var.resc[1:N,1:N] %*% t(lt)

resmcp <- (lt %*% resc[1:N] )/sqrt(diag(var.resmcp))
```

```{r}
plot(x=distribution = "Normal", y = resmcp)
```


Variance of predicted errors for the random effects:
\begin{align*}
Var(\hat{\mathbf{b}}_i - \mathbf{b}_i) &= Var(\hat{\mathbf{b}}_i) + Var(\mathbf{b}_i) - Cov(\mathbf{b}_i, \hat{\mathbf{b}}_i) - Cov(\hat{\mathbf{b}}_i, \mathbf{b}_i) \\
&=Var(\mathbf{\Gamma Z^\top Q y}) + Var(\mathbf{b}_i) - Cov(\mathbf{\Gamma Z^\top Q y}, \mathbf{b}_i) - Cov(\mathbf{b}_i, \mathbf{\Gamma Z^\top Q y})
&=\mathbf{\Gamma Z^\top Q Z \Gamma} + \mathbf{\Gamma} - 2 \mathbf{\Gamma Z^\top Q Z \Gamma} \\
&= \mathbf{\Gamma} - \mathbf{\Gamma Z^\top Q Z \Gamma} + \mathbf{\Gamma}
\end{align*}

```{r}
pred.er.var <- Gam - Gam %*% t(Z) %*% Q %*% Z %*% Gam
Mi <- t(b_hat) %*% MASS::ginv(pred.er.var) %*% b_hat
Gam
pred.er.var
```

```{r}
pred.er.var[1:8,1:8]
```

```{r}
b_hat[1:2]
```







```{r values}

count(df, gen)# what is the within unit

# simulate y
MASS::mvrnorm(n = 1, mu = X %*% beta_hat, Sigma = Sigma)

Sigmai_sqrt <- expm::sqrtm(fit$Vi)

# residuals

# random effects residuals
resre <- Z %*% b_hat; resre <- resre[,1]

vareps <- Sigmai_sqrt %*% resm; vareps <- vareps[,1]
tvar <- Sigma - X %*% solve(t(X) %*% Sigmai %*% X) %*% t(X)
smres <- resm/sqrt(diag(tvar))

df2 <- tibble(y, resm, resc, resre, smres, fitted = fit$fitted[,1])
```

```{r plot 1}
ggplot(data = df2, mapping = aes(x = fitted, y = smres)) +
  geom_point() + geom_hline(color = "red", yintercept = 0)
```

```{r plot2}
ggplot(data = df2, mapping = aes(x = 1:nrow(df), y = smres)) +
  geom_point() + geom_hline(color = "red", yintercept = 0)
```

```{r adequacy measure of the within-unit covariance structure}
I32 <- diag(32)

Vi <- Matrix::norm(x = I32 - vareps %*% t(vareps), type = "2")
stdVi <- sqrt(Vi)/32
```

???? quit confused with how to figure out the within-unit covariance structure Vi, from above it is just a scalar.
```{r plot 3}

```

```{r}
Q <- Sigmai - Sigmai %*% X %*% solve(t(X) %*% Sigmai %*% X) %*% t(X) %*% Sigmai
#G <- matrix(unlist(fit$VarU), 8,8) # this may not be correct

mat1 <- matrix(c(as.vector(fit$VarU[[1]]$yield), rep(0, 16)), 4, 8)
mat2 <- matrix(c(rep(0, 16), as.vector(fit$VarU[[2]]$yield)), 4, 8)
G <- rbind(mat1, mat2)

R <- Sigma - Z %*% G %*% t(Z)

vare_hat <- R %*% Q %*% R

resc <- y - X %*% beta_hat - Z %*% b_hat; resc <- resc[,1]
scres <- resc/sqrt(diag(vare_hat))

df3 <- tibble(y, resc, scres, fitted = fit$fitted[,1])
```

Presence of outlying observations ($\mathbf{y}_{ij}$)
```{r plot 4}
ggplot(df3, aes(1:nrow(df), scres)) + geom_point() +
  geom_hline(yintercept = 0, color = "red")
```

There may be an outlying observation at the left right coner..

Homoskedasticity of conditional errors ($\mathbf{e}_{ij}$)
```{r plot 5}
ggplot(df3, aes(fitted, scres)) + geom_point() +
  geom_hline(color = "red", yintercept = 0)
```


Normality of conditional errors
```{r plot 6}

```
how to get the $\mathbf{L}$ and $\Lambda$??
Is the $\mathbf{L}$ comes from unit-specific linear combinations of the form
$$\mathbf{L}_i = \mathbf{K}_1^\top \boldsymbol{\beta} + \mathbf{K}_2^\top \mathbf{b}_i$$

How to know $\mathbf{K}_1$ and $\mathbf{K}_$..

```{r}
pev <- fit$PevU
mat1 <- matrix(c(as.vector(fit$VarU[[1]]$yield), rep(0, 16)), 4, 8)
mat2 <- matrix(c(rep(0, 16), as.vector(fit$VarU[[2]]$yield)), 4, 8)
matrix(c(as.vector(fit$PevU[[1]]$yield)),4,4)
matrix(c(as.vector(fit$PevU[[2]]$yield)),4,4)

M <- matrix(c((fit$PevU[[1]]$yield)))
```

Presence of outlying subjects
```{r plot 7}

```

Normality of the random effects
```{r plot 8}

```

