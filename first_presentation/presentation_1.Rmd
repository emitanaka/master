---
title: "Visual Inference for Graphcial Diagnostic of Linear Mixed Models"
subtitle: "Supervisor: Dr Emi Tanaka & Prof Di Cook"
author: "Kaiwen Jin"
institute: "Monash University"
date: "2020-09-18"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      ratio: '16:9'
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      bibliography: ref.bib
      link-citations: yes
---
```{r include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(xaringanthemer)
library(lme4)
library(tidyverse)
library(ggbeeswarm)
library(colorspace)
library(ggplot2)
library(nullabor)
library(qqplotr)
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE#,
  #cache.path = "cache/",
  #cache = TRUE
)
```

```{r xaringan-themer, include=FALSE, warning=FALSE}
style_mono_accent(
  base_color = "#1c5253",
  #header_font_google = google_font("Cabin"),
  #text_font_google   = google_font("Note Sans", "300", "300i"),
  #code_font_google   = google_font("IBM Plex Mono")
)
```

```{css, echo = FALSE}
.footnote { position: absolute; bottom:0; }
```

## Linguistic Case

### Data
```{r include=FALSE}
df <- read_csv('~/Desktop/Masters/Master_Econometrics/S2 2020/ETF5550/master/data/politeness_data.csv') %>% 
  mutate(scenario = fct_reorder(factor(scenario), frequency, function(x) mean(x, na.rm = TRUE)),
         subject = fct_reorder(subject, frequency, function(x) mean(x, na.rm = TRUE)))
df <- na.omit(df)
```

.pull-left[
- Gender (female or male)

- Attitude (informal or polite)

- 6 subjects (3 male and 3 female)

- 7 scenarios (such as excusing for coming too late)

- Frequency (also called voice pitch)
]

--
.pull-right[

#### frequency ~ gender + $\varepsilon$

```{r gender, fig.height=4.5, dev='svg'}
ggplot(df, aes(gender, frequency)) + 
  geom_point() + 
  stat_smooth(aes(group = 1), method = "lm", se = FALSE) +
  ylab("Frequency \\ Voice Pitch") + xlab("Gender")
```
]

???

Here i'd like to introduce you a linguistic case. There are 84 observations in the dataset with one missing value. The top 4 categorical variables are the independent variables and the last one is the dependent variable `frequency which is also called voice pitch`.

If we fit the linear model such as frequency is a function of gender. From this plot we can see that the overall female voice pitch is higher than the male.

But how does the frequency differ with different subjects?

---
class: inverse, middle, center

### With different subjects

```{r subject, fig.height=5, fig.width=10, dev='svg'}
ggplot(df, aes(attitude, frequency, fill = gender)) + 
  geom_boxplot() + 
  facet_grid(~subject) +
  geom_beeswarm(color = "#383838") +
  scale_fill_discrete_qualitative(name = "Gender",
                                  labels = c("Female", "Male")) +
  scale_x_discrete(labels = c("Informal", "Polite")) +
  ylab("Frequency \\ Voice Pitch") + xlab("Attitude")
```

---
class: inverse, middle, center

### With different scenarios

```{r scenario, fig.height=5,fig.width=10, dev='svg'}
ggplot(df, aes(scenario, frequency)) + geom_boxplot() + geom_beeswarm(aes(color = gender)) + scale_color_discrete_qualitative(name = "Gender", labels = c("Female", "Male")) + ylab("Frequency \\ Voice Pitch") + xlab("Scenario")
```

---

## Linear Mixed Model
--
.center[$$\boldsymbol{y = X\beta + Zb + e}$$]

where

.pull-left[
- $\mathbf{y}$ is a $\mathbf{N \times 1}$ vector of observations, outcome variable
- $\mathbf{X}$ is a $\mathbf{N \times p}$ matrix
- $\boldsymbol\beta$ is a $\mathbf{p \times 1}$ vector of the fixed effect
- $\mathbf{Z}$ is a $\mathbf{N \times q}$ matrix
- $\mathbf{b}$ is a $\mathbf{q \times 1}$ vector of the random effect
]

.pull-right[
\begin{align*}
   \begin{bmatrix}
      \mathbf{b} \\ \mathbf{e}
   \end{bmatrix}
   \sim \mathcal{N}\left(\begin{bmatrix}\mathbf{0} \\ \mathbf{0} \end{bmatrix}, \begin{bmatrix} \mathbf{\Gamma} & \mathbf{0} \\ \mathbf{0} & \mathbf{R} \end{bmatrix}\right)
\end{align*}

\begin{align*}
  \mathbf{y} \sim \mathcal{N} (\boldsymbol{X\beta}, \mathbf\Omega = \boldsymbol{Z\Gamma Z^\top + R})
\end{align*}
  ]
  
--

How can we implement the LME?
- `lmer` function from `lme4` package
- `mmer` function from `sommer` package

.footnote[
<br><span style=“font-size:3pt”>Douglas Bates, Martin Maechler, Ben Bolker, Steve Walker (2015). Fitting Linear Mixed-Effects Models Using lme4. Journal of Statistical Software, 67(1), 1-48. doi:10.18637/jss.v067.i01. </span>
]

???

The formula for the linear mixed model is shown like this. Y is the response variable, X and Z are designed matrices for the fixed and random effects respectively. Beta is the fixed effects. B refers to the random effect. Epsilon denotes the error term which follows an identical independent normal distribution. The marginal distribution of y is normally distributed with mean X times beta and variance Omega. We often use these two functions to build the linear mixed model from the lme4 and sommer packages.

---

## Graphical diagnostic on residual analysis

Types of residuals and corresponding residual diagnostic purpose:
.pull-left[
- Marginal residuals, $\boldsymbol{\hat\xi = y - X\hat \beta}$
    + Linear of the effects fixed 
    + Presence of outlying observations
    + Within-units covariance matrix 
      
- Random effect residuals, $\mathbf{Z\hat b}$
      + Presence of outlying subjects 
      + Normality of the random effects 
]
.pull-right[
- Conditional residuals, $\boldsymbol{\hat e = y - X\hat \beta - Z\hat b}$
    + Presence of outlying observations 
    + Homoskedasticity of conditional errors 
    + Normality of conditional errors 
]
    
.footnote[
<span style=“font-size:3pt”>[1.]Haslett, J., & Haslett, S. J. (2007). The three basic types of residuals for a linear model. International Statistical Review, 75(1), 1-24. Chicago <br>[2.]Singer, J. M., Rocha, F. M., & Nobre, J. S. (2017). Graphical tools for detecting departures from linear mixed model assumptions and some remedial measures. International Statistical Review, 85(2), 290-324. <br>[3.]Loy, A., Hofmann, H., & Cook, D. (2017). Model choice and diagnostics for linear mixed-effects models using statistics on street corners. Journal of Computational and Graphical Statistics, 26(3), 478-492.</span>
]

???

According to Haslett’s literature, there are 3 residuals in the linear mixed model. There are marginal residuals, conditional residuals and random effect residuals. And the following are the main purposes of graphical diagnostics for different residuals indicated by Singer. These diagnostic plots are similar to the test statistics in the classical statistical inference which will talk later. In Adam Loy’s paper, they mainly focus on the conditional residual and random effect residuals. They have already talked about the homogeneity of residual variance and linearity on the conditional residuals as well as the distribution assessment for the random effects residual. Here I mainly focus on the presence of outlying observations for the marginal residuals and the normality of the conditional errors in the linguistic case.
---

### Presence of outlying observations

.pull-left[
- Subject

```{r setup, include = FALSE}
fit <- lmer(frequency ~ attitude + gender + 
              (1|subject) + (1|scenario),
            data = df)

N <- nrow(df)
subjects <- unique(df$subject)
nsubject <- length(subjects)
scenarios <- unique(df$scenario)
nscenario <- length(scenarios)
y <- df$frequency
X <- model.matrix(~attitude + gender, data = df)
beta <- fixef(fit)
Z1 <- model.matrix(~subject - 1, data = df)
Z2 <- model.matrix(~scenario - 1, data = df)
Z <- cbind(Z1, Z2)
u <- c(ranef(fit)$subject[,1], ranef(fit)$scenario[,1])
q <- length(u)
vc <- as.data.frame(VarCorr(fit))
R <- vc$vcov[vc$grp=="Residual"] * diag(N)
G1 <- vc$vcov[vc$grp=="subject"] * diag(nsubject)
G2 <- vc$vcov[vc$grp=="scenario"] * diag(nscenario)
G <- Matrix::bdiag(G1, G2)
Sigma <- Z %*% G %*% t(Z)  + R
Sigma_inv <- solve(Sigma)
varMargRes <- Sigma - X %*% solve(t(X) %*% solve(Sigma) %*% X) %*% t(X)
P <- Sigma_inv - Sigma_inv %*% X %*% solve(t(X) %*% Sigma_inv %*% X) %*% t(X) %*% Sigma_inv
varCondRes <- R %*% P %*% R
varU <- G - G %*% t(Z) %*% P %*% Z %*% G


fit_df <- df %>% 
  mutate(fitted = as.vector(X %*% beta),
         resm = frequency - fitted, 
         resc = frequency - fitted - as.vector(Z %*% u),
         index = 1:n()) %>% 
  rowwise() %>% 
  mutate(resm_std = resm / sqrt(diag(varMargRes)[index]),
         resc_std = resc / sqrt(diag(varCondRes)[index])) %>% 
  ungroup()

unit_df <- expand_grid(subjects, scenarios) %>% 
  # cannot follow Vi quit well
  mutate(Vi = map2_dbl(subjects, scenarios, ~{
                        ind <- df %>% 
                          mutate(index = 1:n()) %>% 
                          filter(subject==.x,
                                 scenario==.y) %>% 
                          pull(index)
                        mi <- length(ind)
                        # standardised marginal residual
                        Ei <- solve(varMargRes[ind, ind]) %*% fit_df$resm[ind]
                        sqrt(sum((diag(mi) - Ei %*% t(Ei))^2)) / mi
                      }),
         Mi = as.vector(t(u) %*% solve(varU) %*% u)
         )
```

```{r plot2-1, fig.dim=c(4.8, 4.5), out.width="100%", dev='svg'}
ggplot(fit_df, aes(index, resm_std, 
                   color = subject)) + 
  geom_point() + 
  geom_hline(yintercept = 0) + 
  scale_color_discrete_qualitative(name = "Subject") +
  xlab("Observation Index") + ylab("Standardised marginal residual")
```
]

--
.pull-right[

- Scenario

```{r plot2-2, fig.dim=c(4.8, 4.5), out.width="100%", dev='svg'}
fit_df %>% 
  dplyr::arrange(scenario) %>% 
  mutate(index = 1:n()) %>% 
  ggplot(aes(index, resm_std, color = scenario)) + 
  geom_point() + 
  geom_hline(yintercept = 0) + 
  scale_color_discrete_qualitative(name = "Scenario") +
  xlab("Observarion Index") + ylab("Standardised marginal residual")
```

]

???

The presence of outlying observations plot shows the standard marginal residual vs the observation indices. With specifying the subjects, you can see that M7 has all the negative standard marginal residuals. Other than this, there is another subject called M3 whose standard marginal residuals are all positive.
 And it should be the outlier here for the M4 which is close to 3. And there seems to be an outlier for scenario 2 by specifying the scenario condition.

---

### Normality of conditional errors


```{r plot6, fig.height=5,fig.width=10, dev='svg'}
library(qqplotr)
ggplot(fit_df, aes(sample = resc_std)) + 
  stat_qq_band(bandType = "pointwise", fill = "#8DA0CB", qprobs = c(0.25, 0.75), alpha = 0.4) +
  stat_qq_line(colour = "#8DA0CB") +
  stat_qq_point() +
  xlab("Normal quantiles") +
  ylab("Standard conditional residuals")
```

???

Next we can use the plot to see if the simple standardised conditional residuals follows a normal distribution. Have a glance, it seems that it follows the normal distribution but maybo with some **heavy tail**.

Hilden-Minton said the ability to check for normality of the conditional errors increases as minimising the fraction of confounding for the conditional residuals. However, Piepho disaggreed with that. For this point of view, we will check it in the future if the least confounded conditional residual works. 

---

## Lineup Protocol

1. Simulate the new responses
2. Refit the model to these simulated responses
3. Extract the residuals from the proposed model
4. Construct the lineup
5. **Which plot is most different?**

--
#### Visual Inference
- Hypothesis
- Test Statistic: Observed plot
- Sampling Distribution: Lineup
- Desicion Rule: If the observed plot is identifiable, then we can reject the null hypothesis. 

.footnote[
<span style=“font-size:3pt”>[1.]Buja, A., Cook, D., Hofmann, H., Lawrence, M., Lee, E.-K., Swayne, D. F, Wickham, H. (2009) Statistical Inference for Exploratory Data Analysis and Model Diagnostics Royal Society Philosophical Transactions A, 367(1906):4361-4383. http://rsta.royalsocietypublishing.org/content/367/1906/4361.article-info[1.] <br>[2.]Mahbubul Majumder , Heike Hofmann & Dianne Cook (2013) Validation of Visual Statistical Inference, Applied to Linear Models, Journal of the American Statistical Association, 108:503, 942-956, DOI: 10.1080/01621459.2013.808157</span>
]

---
class: inverse, middle, center

```{r simulate, include=FALSE}
# Simulate data for null plots from `fit` model
fit.sim  <- simulate(fit, nsim = 19, seed = 1234)
fit.refit <- lapply(fit.sim, refit, object = fit)
fit.simy <- lapply(fit.refit, function(x) getME(x, "y"))
```

```{r data_nullabor, include=FALSE}
fit.sim.y <- do.call("cbind", fit.simy)
fit.sim.y <- reshape2::melt(fit.sim.y)[-1]
names(fit.sim.y) <- c(".n", "y")
fit.sim.y$.n <- as.numeric(str_extract(fit.sim.y$.n, "\\d+"))
fit.sim.y$attitude <- rep(df$attitude, 19)
fit.sim.y$gender <- rep(df$gender, 19)
fit.sim.y$subject <- rep(df$subject, 19)
fit.sim.y$scenario <- rep(df$scenario, 19)
```

```{r data_simulated, include=FALSE}
simdat <- purrr::map_dfr(1:19, function(i){
  df <- fit.sim.y %>% filter(.n == i) 
  m <- lmer(y ~ attitude + gender + (1|subject) + (1|scenario), data = df)
  
  N <- nrow(df)
  subjects <- unique(df$subject)
  nsubject <- length(subjects)
  scenarios <- unique(df$scenario)
  nscenario <- length(scenarios)
  y <- df$y
  X <- model.matrix(~attitude + gender, data = df)
  beta <- fixef(m)
  Z1 <- model.matrix(~subject - 1, data = df)
  Z2 <- model.matrix(~scenario - 1, data = df)
  Z <- cbind(Z1, Z2)
  u <- c(ranef(m)$subject[,1], ranef(m)$scenario[,1])
  q <- length(u)
  vc <- as.data.frame(VarCorr(m))
  R <- vc$vcov[vc$grp=="Residual"] * diag(N)
  G1 <- vc$vcov[vc$grp=="subject"] * diag(nsubject)
  G2 <- vc$vcov[vc$grp=="scenario"] * diag(nscenario)
  G <- Matrix::bdiag(G1, G2)
  Sigma <- Z %*% G %*% t(Z)  + R
  Sigma_inv <- solve(Sigma)
  varMargRes <- Sigma - X %*% solve(t(X) %*% solve(Sigma) %*% X) %*% t(X)
  P <- Sigma_inv - Sigma_inv %*% X %*% solve(t(X) %*% Sigma_inv %*% X) %*% t(X) %*% Sigma_inv
  varCondRes <- R %*% P %*% R
  varU <- G - G %*% t(Z) %*% P %*% Z %*% G
  
  fitted = as.vector(X %*% beta)
  resm = y - fitted
  resc = y - fitted - as.vector(Z %*% u)
  index = 1:nrow(df)
  resm_std = resm / sqrt(diag(varMargRes)[index])
  resc_std = resc / sqrt(diag(varCondRes)[index])
  
  tibble::tibble(df, fitted, resm_std, resc_std, index)
})
```


```{r turedf, include=FALSE}
colnames(fit_df)[5] <- c("y")
```

```{r lineup_6, fig.height=6, fig.width=10, dev='svg', dev.args=list(bg = "transparent")}
lineup(true = fit_df, samples = simdat, pos = 9) %>% 
  ggplot(aes(sample = resc_std)) +
  stat_qq_band(bandType = "pointwise", fill = "#8DA0CB", qprobs = c(0.25, 0.75), alpha = 0.4) +
  stat_qq_line(colour = "#8DA0CB") +
  stat_qq_point() +
  facet_wrap( ~ .sample, ncol=5)+
  xlab(NULL) + ylab(NULL) + 
  theme(axis.text.y = element_blank(), axis.text.x = element_blank(),
        axis.ticks.x = element_blank(), axis.ticks.y = element_blank(),
        plot.background = element_rect(fill = 'transparent', color = NA))
```

???

For the next plot, we can see that also panel 9 is the most different of the lineup. As there is a heavy tail on the distribution. 

Because of the time constrain, I just show you one dataset. However, I will use diverse dataset to explain maybe some variable are numeric and some are categorical in the future. Although the example is not that sufficient, the graphical diagnostic is suitable for all linear mixed model. And I will keep exploring the easy and interesting way to do the visual inference.

All right. That’s all my presentation. Thank you~

---

## Research Objective
1. Least confounded conditional residuals $\mathbf{c}_k^\top \hat{\mathbf{e}}$ v.s Standardised conditional residuals

2. Presence of outlying observation:
  - Marginal residual v.s Conditional residuals

## Research Plan

Do a **user study**

.footnote[
<span style=“font-size:7pt”>[1.]Loy, A., Hofmann, H., & Cook, D. (2017). Model choice and diagnostics for linear mixed-effects models using statistics on street corners. Journal of Computational and Graphical Statistics, 26(3), 478-492. <br>[2.]Hilden-Minton, J.A. (1995). Multilevel diagnostics for mixed and hierarchical linear models, Unpublished PhD Thesis, University of California, Los Angeles. <br>[3.]Schützenmeister, A. & Piepho, H.P. (2012). Residual analysis of linear mixed models using a simulation approach. Comput. Stat. Data Anal., 56, 1405–1416.</span>
]
